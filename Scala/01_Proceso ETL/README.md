# ğŸ”¥ OptimizaciÃ³n y Patrones Avanzados en Apache Spark

## ğŸš€ IntroducciÃ³n
La optimizaciÃ³n en Apache Spark es clave para mejorar el rendimiento y eficiencia en el procesamiento de grandes volÃºmenes de datos. En este documento exploraremos tÃ©cnicas avanzadas como:

- **Repartition & Coalesce** ğŸ§©
- **Cache & Persist** âš¡
- **Checkpointing** âœ…

TambiÃ©n proporcionaremos ejemplos prÃ¡cticos y cuÃ¡ndo **NO** usarlos. 

---

## ğŸ”„ Repartition & Coalesce

### ğŸ“Œ Â¿QuÃ© es `repartition()`?
`repartition(n)` redistribuye los datos en `n` particiones, utilizando un **shuffle** costoso. Se recomienda en los siguientes casos:

âœ… Cuando se necesita una distribuciÃ³n **mÃ¡s equilibrada** de los datos.  
âœ… Para mejorar el **paralelismo** en operaciones intensivas.  
âœ… Cuando se leen archivos con un nÃºmero ineficiente de particiones.

ğŸ”´ **Ejemplo de uso**:
```scala
val df = spark.read.parquet("/data/dataset.parquet")
val dfRepartitioned = df.repartition(10) // Redistribuye en 10 particiones
```

### ğŸ“Œ `coalesce(n)`, una alternativa eficiente
A diferencia de `repartition()`, `coalesce(n)` **reduce** el nÃºmero de particiones sin un shuffle completo. Es Ãºtil en los siguientes casos:

âœ… DespuÃ©s de una transformaciÃ³n que reduce los datos significativamente.  
âœ… Para mejorar el rendimiento en escrituras a disco.  

ğŸ”´ **Ejemplo de uso**:
```scala
val dfOptimized = df.repartition(10).coalesce(5) // Reduce a 5 particiones sin shuffle completo
```

ğŸš¨ **No usar `coalesce()` si necesitas un balance uniforme de datos**, ya que puede generar particiones desiguales.

---

## âš¡ Cache & Persist

### ğŸ“Œ `cache()`: Almacenar temporalmente en memoria
`cache()` almacena el **DataFrame en memoria RAM** para acelerar mÃºltiples reutilizaciones.

âœ… Ãštil cuando se reutiliza un DataFrame varias veces en una sesiÃ³n.  
âœ… Reduce el tiempo de cÃ³mputo en operaciones repetitivas.  

ğŸ”´ **Ejemplo de uso**:
```scala
val dfCached = df.cache()
dfCached.show() // Primera ejecuciÃ³n carga los datos en memoria
dfCached.count() // Segunda ejecuciÃ³n serÃ¡ mÃ¡s rÃ¡pida
```

ğŸš¨ **No usar `cache()` si los datos son demasiado grandes para la memoria**, ya que puede generar errores de `OutOfMemory`.

### ğŸ“Œ `persist()`: Control de almacenamiento en memoria y disco
`persist(StorageLevel.MEMORY_AND_DISK)` permite elegir cÃ³mo almacenar los datos:

| Nivel de Persistencia | UbicaciÃ³n | Evita pÃ©rdida de datos |
|-----------------------|-----------|-----------------------|
| `MEMORY_ONLY`       | Solo RAM  | âŒ No |
| `MEMORY_AND_DISK`   | RAM y Disco | âœ… SÃ­ |
| `DISK_ONLY`         | Solo Disco | âœ… SÃ­ |

ğŸ”´ **Ejemplo de uso**:
```scala
import org.apache.spark.storage.StorageLevel
val dfPersisted = df.persist(StorageLevel.MEMORY_AND_DISK)
```

ğŸš¨ **Usar `persist()` en lugar de `cache()` cuando los datos no caben en memoria**.

---

## âœ… Checkpointing: Persistencia a largo plazo

### ğŸ“Œ Â¿QuÃ© es `checkpoint()`?
`checkpoint()` guarda los datos en **disco HDFS** o almacenamiento distribuido, eliminando la dependencia de DAG anterior.

âœ… Ãštil en flujos de datos largos o iterativos (como algoritmos de ML).  
âœ… Reduce la acumulaciÃ³n de linaje de RDDs, evitando problemas de memoria.  

ğŸ”´ **Ejemplo de uso**:
```scala
spark.sparkContext.setCheckpointDir("/tmp/checkpoints")
val dfCheckpointed = df.checkpoint()
```

ğŸš¨ **No usar `checkpoint()` para pequeÃ±os DataFrames temporales**, ya que introduce I/O innecesario.

---

## ğŸ“š Recursos Adicionales
ğŸ“– Para mÃ¡s informaciÃ³n, consulta la documentaciÃ³n oficial de Spark:  
ğŸ”— [OptimizaciÃ³n en Spark](https://spark.apache.org/docs/latest/tuning.html)  

ğŸ¯ Con estas estrategias, puedes mejorar significativamente el rendimiento de Spark y evitar cuellos de botella. ğŸš€
